---
title: "Ai FinalProject"
output: html_document
date: "2023-10-31"
---

![](https://external-content.duckduckgo.com/iu/?u=https%3A%2F%2Ftse1.mm.bing.net%2Fth%3Fid%3DOIP.pyUGZ-JSCxuLAPnKFvnJNAHaBu%26pid%3DApi&f=1&ipt=1bf7a7108e5456fa82bdf8126bc3fa2b6d808b399b946c20f0e1182e67c751aa&ipo=images)





> *Professor Dr. Feng-Jen Yang *^[Florida Polytechnic University, fyang@floridapoly.edu ]<br>

> *Claire Robinson *^[Florida Polytechnic University, crobinson9123@floridapoly.edu]
> *Marckenrold Cadet *^[Florida Polytechnic University, mcadet6565@floridapoly.edu]
> *Students Rene Perez*^[Florida Polytechnic University, rperez8013@floridapoly.edu]


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```




```{r echo=FALSE,message=FALSE,results='hide', warning=FALSE}



RequiredPackages <- c("ROCR","tidyverse","dplyr","stringr","lubridate","ggcorrplot","factoextra", "dbscan", "cluster", 'caret', 'car', "MASS", "xfun","popbio","zoo", "doBy", "ISLR", "dynlm","lmerTest", "dynamac", "Deriv", "microbenchmark", "collapse", "leaps","stargazer", "lme4","lmerTest", "ISLR2", "glmnet", "gam", "tree", "randomForest", "plotly", "broom", "knitr","randomForestExplainer")
for (i in RequiredPackages) { #Installs packages if not yet installed
    if (!require(i, character.only = TRUE)) install.packages(i)}


library(ISLR2)
library(lmerTest)
library(randomForest)
library(stargazer)
library("tidyverse")
library("dplyr")
library(dplyr)
library(stringr)
library(lubridate)
library(MASS)
library(leaps)
library(lme4)
library(gam)
library(dynlm)
library(tree)
 
library(MASS)
library(dynamac)
 
library(dplyr)
library(plyr)
library(glmnet)
library(plotly)
library(broom)
library(nlme)
library(knitr)
#library(reprtree)
library(randomForestExplainer)
```

### Importing database

```{r}

data = read.csv("bases/Database.csv",header = T)



```

### Summary Statistics

```{r}


data <- data %>% drop_na()

glimpse(data)
summary(data)


```


```{r}



correlation   <-cor(data[-(1:2)], use = "all.obs", method = c("pearson"))
  
  

 
 ggcorrplot(correlation)+
   labs(title = "Correlation Maxtrix")

 


    
```

### Linear Regression
#### Extracting equation to optimize

```{r}
lr <- lm(interest_Rate ~ BusinessApplications + ConstructionSpending + DurableGoodsNewOrders +
         InternationalTrade_Exports + InternationalTrade_Imports + ManuInventories +  ManuNewOrders +
         NewHomesForSale +  NewHomesSold  +  ResConstPermits +  ResConstUnitsCompleted + ResConstUnitsStarted + RetailInventories + SalesForRetailAndFood + WholesaleInventories + consumerIndex + UNRATE
         
         , data = data)
summary(lr)
```


```{r}
plot(predict(lr, data = data))
```

### GA Algorithm

```{python}
import numpy

# This project is extended and a library called PyGAD is released to build the genetic algorithm.
# PyGAD documentation: https://pygad.readthedocs.io
# Install PyGAD: pip install pygad
# PyGAD source code at GitHub: https://github.com/ahmedfgad/GeneticAlgorithmPython

def cal_pop_fitness(equation_inputs, pop):
    # Calculating the fitness value of each solution in the current population.
    # The fitness function caulcuates the sum of products between each input and its corresponding weight.
    fitness = numpy.sum(pop*equation_inputs, axis=1)
    return fitness

def select_mating_pool(pop, fitness, num_parents):
    # Selecting the best individuals in the current generation as parents for producing the offspring of the next generation.
    parents = numpy.empty((num_parents, pop.shape[1]))
    for parent_num in range(num_parents):
        max_fitness_idx = numpy.where(fitness == numpy.max(fitness))
        max_fitness_idx = max_fitness_idx[0][0]
        parents[parent_num, :] = pop[max_fitness_idx, :]
        fitness[max_fitness_idx] = -99999999999
    return parents

def crossover(parents, offspring_size):
    offspring = numpy.empty(offspring_size)
    # The point at which crossover takes place between two parents. Usually it is at the center.
    crossover_point = numpy.uint8(offspring_size[1]/2)

    for k in range(offspring_size[0]):
        # Index of the first parent to mate.
        parent1_idx = k%parents.shape[0]
        # Index of the second parent to mate.
        parent2_idx = (k+1)%parents.shape[0]
        # The new offspring will have its first half of its genes taken from the first parent.
        offspring[k, 0:crossover_point] = parents[parent1_idx, 0:crossover_point]
        # The new offspring will have its second half of its genes taken from the second parent.
        offspring[k, crossover_point:] = parents[parent2_idx, crossover_point:]
    return offspring

def mutation(offspring_crossover):
    # Mutation changes a single gene in each offspring randomly.
    for idx in range(offspring_crossover.shape[0]):
        # The random value to be added to the gene.
        random_value = numpy.random.uniform(-1.0, 1.0, 1)
        offspring_crossover[idx, 4] = offspring_crossover[idx, 4] + random_value
    return offspring_crossover
```

### Coefficients from Lr

```{python}

import numpy

# Inputs of the equation.
equation_inputs = [-2.68E-06,	-1.01E-05,	1.69E-05,	5.25E-06,	-2.57E-05,	-2.18E-06,	4.08E-06,	1.80E-02,	3.08E-03,	-1.37E-03,	1.67E-03,	-4.44E-04,	1.69E-05,	2.28E-06,	-1.72E-05,	-2.99E+01,	-9.86E-02]
 # Number of the weights we are looking to optimize.
num_weights = 17




```



```{python}

sol_per_pop = 150
num_parents_mating = 2

```


```{python}

# Defining the population size.
pop_size = (sol_per_pop,num_weights) # The population will have sol_per_pop chromosome where each chromosome has num_weights genes.
#Creating the initial population.
new_population = numpy.random.uniform(low=-1.37E-03
, high=1.80E-02
, size=pop_size)
print(new_population)

num_generations = 100
for generation in range(num_generations):
    print("Generation : ", generation)
    # Measing the fitness of each chromosome in the population.
    fitness = cal_pop_fitness(equation_inputs, new_population)

    # Selecting the best parents in the population for mating.
    parents = select_mating_pool(new_population, fitness, 
                                      num_parents_mating)

    # Generating next generation using crossover.
    offspring_crossover = crossover(parents,
                                       offspring_size=(pop_size[0]-parents.shape[0], num_weights))

    # Adding some variations to the offsrping using mutation.
    offspring_mutation = mutation(offspring_crossover)

    # Creating the new population based on the parents and offspring.
    new_population[0:parents.shape[0], :] = parents
    new_population[parents.shape[0]:, :] = offspring_mutation

    # The best result in the current iteration.
    print("Best result : ", numpy.max(numpy.sum(new_population*equation_inputs, axis=1)))

# Getting the best solution after iterating finishing all generations.
#At first, the fitness is calculated for each solution in the final generation.
fitness = cal_pop_fitness(equation_inputs, new_population)
# Then return the index of that solution corresponding to the best fitness.
best_match_idx = numpy.where(fitness == numpy.max(fitness))

print("Best coefficients : ", new_population[best_match_idx, :])
print("Best Interest rate : ", fitness[best_match_idx]*100)


```

```{python}


import matplotlib.pyplot as plt
plt.plot(fitness)

plt.title("Best interest rate over (230 months)")
plt.suptitle("Octuber 1994 - Sept 2023 ")
plt.xlabel("Generations Selected") 
plt.ylabel("Interest Rate") 

plt.show()


```


### What it is the best interest rate? Function to find it from customer perspective

```{python}
#pip install geneticalgorithm


import numpy as np
from geneticalgorithm import geneticalgorithm as ga

#define the fitness the equations

def fitness_function(x):
    x1 = x[0]
    x2 = x[1]
    x3 = x[2]
    x4 = x[3]
    x5 = x[4]
    x6 = x[5]
    x7 = x[6]
    x8 = x[7]
    x9 = x[8]
    x10 = x[9]
    x11 = x[10]
    x12 = x[11]
    x13 = x[12]
    x14 = x[13]
    x15 = x[14]
    x16 = x[15]
    x17 = x[16]
    
    #apply constraints

    penalty = 0
    
    if  -2.680e-06*x1 + -0.00001014*x2 + 0.00001686*x3 + 0.000005249*x4 + -0.00002568*x5 + -0.000002184*x6 + 0.000004081*x7 + 0.018*x8 + 0.003076*x9 + -0.001368*x10 + 0.001669*x11 + -0.0004439*x12 + 0.00001685*x13 + 0.000002279*x14 + -0.0000172*x15 + 0.1582*x16 + -0.09859*x17 > fitness[best_match_idx]:
        penalty = np.inf
        
    return - (-2.680e-06*x1 + -0.00001014*x2 + 0.00001686*x3 + 0.000005249*x4 + -0.00002568*x5 + -0.000002184*x6 + 0.000004081*x7 + 0.018*x8 + 0.003076*x9 + -0.001368*x10 + 0.001669*x11 + -0.0004439*x12 + 0.00001685*x13 + 0.000002279*x14 + -0.0000172*x15 + 0.1582*x16 + -0.09859*x17) + penalty
    
    ## negative because genetic algoritim will always max and we want to min

# create an instance of the GA solver


model = ga(function = fitness_function, dimension = 17, variable_type = 'bool' )


model.run()


```

```{r}
lmInflation<- lm( UNRATE ~interest_Rate , data = data)

summary(lmInflation)
```



### When we thing that Fed will stop increasing the interest rate


```{python}

def fitness(x):
    x1 = x[0]
    
    #apply constraints

    penalty = 0
    
    if  -0.66739*x1   > 0.023:
        penalty = np.inf
        
    return  (-0.66739*x1 ) + penalty + 6.89988
  
  # create an instance of the GA solver


modelInf = ga(function = fitness, dimension = 1, variable_type = 'bool' )

modelInf.run()

```

